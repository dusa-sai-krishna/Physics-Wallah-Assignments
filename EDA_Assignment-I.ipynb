{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1\n",
    "\n",
    "Fixed Acidity: Fixed acidity refers to the amount of non-volatile acids in the wine. These acids play a crucial role in the overall taste and balance of the wine. Wines with an appropriate level of fixed acidity tend to have a better structure and a refreshing taste.\n",
    "\n",
    "Volatile Acidity: Volatile acidity represents the presence of volatile acids, primarily acetic acid, in the wine. High levels of volatile acidity can result in unpleasant vinegar-like flavors and spoil the wine's quality.\n",
    "\n",
    "Citric Acid: Citric acid is a naturally occurring acid found in citrus fruits. It can contribute to the wine's freshness and add a citrusy aroma and flavor. In moderation, citric acid can enhance the wine's overall quality.\n",
    "\n",
    "Residual Sugar: Residual sugar refers to the amount of sugar that remains unfermented in the wine. It can influence the wine's sweetness and balance. Some wine styles, like dessert wines, have higher residual sugar, while dry wines have minimal residual sugar.\n",
    "\n",
    "Chlorides: Chlorides represent the concentration of salt in the wine. While a small amount of chloride can enhance the wine's flavor, excessive levels can make the wine taste salty and unpalatable.\n",
    "\n",
    "Free Sulfur Dioxide: Free sulfur dioxide acts as a preservative in wine, preventing oxidation and the growth of undesirable microorganisms. Proper levels of free sulfur dioxide are essential for wine quality and stability.\n",
    "\n",
    "Total Sulfur Dioxide: Total sulfur dioxide is the sum of both free and bound sulfur dioxide. It is a measure of the wine's overall sulfur dioxide content, which is important for wine preservation and preventing spoilage.\n",
    "\n",
    "Density: Density is a measure of the wine's mass per unit volume. It can provide information about the wine's concentration and body. Density can be related to the wine's alcohol content and sweetness.\n",
    "\n",
    "pH: pH measures the acidity or alkalinity of the wine. It plays a significant role in the wine's stability and balance. Proper pH levels are critical for winemaking and the wine's overall quality.\n",
    "\n",
    "Sulphates: Sulphates, specifically in the form of potassium sulphate, are used in winemaking as a preservative and antioxidant. They help prevent spoilage and maintain the wine's freshness.\n",
    "\n",
    "Alcohol: Alcohol content is a key factor in wine quality. It affects the wine's body, aroma, and flavor. Wines with appropriate alcohol levels are generally considered more balanced and enjoyable.\n",
    "\n",
    "Quality: This is the target variable that you want to predict. It represents the overall quality of the wine, typically rated on a scale from 3 to 9 (or similar). This rating is based on sensory evaluations by experts or consumers and summarizes the combined impact of all the other attributes on the wine's quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2\n",
    "\n",
    "Wine quality dataset do not have any missing values to handle\n",
    "\n",
    "Imputation techniques like mean, median, mode, and target attribute-based imputation have their own advantages and disadvantages. Here's a brief overview of each:\n",
    "\n",
    "**Mean Imputation:**\n",
    "\n",
    "**Advantages:**\n",
    "1. **Simple and Fast:** Mean imputation is straightforward to implement and computationally efficient.\n",
    "2. **Preserves Sample Size:** It keeps the sample size constant, as it replaces missing values with the mean of the available data.\n",
    "3. **Useful for Continuous Data:** It is well-suited for continuous numerical data.\n",
    "\n",
    "**Disadvantages:**\n",
    "1. **May Introduce Bias:** If data is not missing completely at random (MCAR), mean imputation can introduce bias by assuming that missing values have the same distribution as observed values.\n",
    "2. **Reduces Variability:** It underestimates the variability in the data because all imputed values are the same (the mean).\n",
    "\n",
    "**Median Imputation:**\n",
    "\n",
    "**Advantages:**\n",
    "1. **Robust to Outliers:** Median is less sensitive to outliers compared to mean, making it a better choice when the data contains extreme values.\n",
    "2. **Simple:** Similar to mean imputation, median imputation is easy to apply.\n",
    "\n",
    "**Disadvantages:**\n",
    "1. **Limited to Numerical Data:** Median imputation is suitable only for numerical data.\n",
    "2. **Ignores Relationships:** Like mean imputation, it doesn't consider relationships between variables, potentially missing out on valuable information.\n",
    "\n",
    "**Mode Imputation:**\n",
    "\n",
    "**Advantages:**\n",
    "1. **Suitable for Categorical Data:** Mode imputation is appropriate for handling missing values in categorical variables.\n",
    "2. **Maintains Data Distribution:** It preserves the original distribution of categorical data.\n",
    "\n",
    "**Disadvantages:**\n",
    "1. **Limited to Categorical Data:** Mode imputation is not applicable to continuous numerical data.\n",
    "2. **May Not Represent Data Well:** The mode might not be a representative value if the data is not well-distributed across categories.\n",
    "\n",
    "**Target Attribute-Based Imputation:**\n",
    "\n",
    "**Advantages:**\n",
    "1. **Utilizes Relationships:** This technique takes into account the relationships between the target attribute (the attribute for which you're imputing missing values) and other variables.\n",
    "2. **Can Improve Predictive Accuracy:** It can potentially lead to better imputations, especially when there are strong relationships between variables and the target attribute.\n",
    "\n",
    "**Disadvantages:**\n",
    "1. **Complex:** Implementing target attribute-based imputation can be more complex than simple statistical imputations.\n",
    "2. **Data Leakage:** Care must be taken to avoid data leakage when using this technique. Leakage occurs when information from the target attribute is used to impute missing values, potentially leading to overfitting in predictive modeling.\n",
    "\n",
    "The choice of imputation technique depends on the nature of the data, the specific goals of the analysis, and the underlying assumptions about the missing data mechanism. It's important to carefully consider the trade-offs and limitations of each technique and select the one that best fits the context of the problem and the dataset in question. Additionally, for target attribute-based imputation, it's crucial to properly validate and evaluate the performance of the imputation model to ensure it doesn't introduce bias or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3\n",
    "\n",
    "\n",
    "As per the EDA on the student performance dataset. Students who eat standard lunch and who have taken test_prep course tend to perform better. Hence, I think these factors are dominant. \n",
    "\n",
    "For categorical features like gender, race_ethnicity, parental_level_of education I would use visualization techniques to understand their impact with various attributes. \n",
    "\n",
    "For numerical features, correlation analysis would suffice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4\n",
    "\n",
    "Feature Engineering is a process of modifying features of a dataset to make it ready for analysis and model training. This involves following steps\n",
    " \n",
    "- Handling missing values using Imputation methods\n",
    "- Handling outliers\n",
    "- Handling duplicate values\n",
    "- Rebalancing datasets\n",
    "- Maintaining consistency of the datasets\n",
    "\n",
    "In student performance dataset. I have done following actions under EDA\n",
    "- I checked for duplicates, but they were not present.\n",
    "- I checked for missing values, but they were not present.\n",
    "- I combined all numerical features (math_score,reading_score, writing_score) as total_score.\n",
    "- Created seperate list objects for categorical and numerical features.\n",
    "- For categorical features, which are unordered , I will label encoding.\n",
    "- For categorical features, which are ordered, I would use Ordered encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5\n",
    "\n",
    "* Insights and Obseravations *\n",
    "\n",
    "** Right_Skewed ** Use Natural Log transformation\n",
    "- Fixed_acidity\n",
    "- Volatile_acidity\n",
    "- Citric_acid\n",
    "- Chlorides\n",
    "- Free_Sulphur_dioxide\n",
    "- total_Sulphur_dioxide\n",
    "- Residual_sugar\n",
    "- Sulphates\n",
    "- alcohol\n",
    "\n",
    "** Normal **\n",
    "- Density\n",
    "- Ph\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "data=pd.read_csv('winequality-red.csv')\n",
    "data.head()\n",
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X is your feature matrix\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28173931, 0.45682201, 0.59778051, 0.70807438, 0.79528275,\n",
       "       0.85524714, 0.90831906, 0.94676967, 0.97810077, 0.99458561,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "cumulative_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = np.argmax(cumulative_variance >= 0.90) + 1\n",
    "n_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.61952988,  0.45095009, -1.77445415, ...,  0.06701448,\n",
       "        -0.91392069, -0.16104319],\n",
       "       [-0.79916993,  1.85655306, -0.91169017, ..., -0.01839156,\n",
       "         0.92971392, -1.00982858],\n",
       "       [-0.74847909,  0.88203886, -1.17139423, ..., -0.04353101,\n",
       "         0.40147313, -0.53955348],\n",
       "       ...,\n",
       "       [-1.45612897,  0.31174559,  1.12423941, ...,  0.19371564,\n",
       "        -0.50640956, -0.23108221],\n",
       "       [-2.27051793,  0.97979111,  0.62796456, ...,  0.06773549,\n",
       "        -0.86040762, -0.32148695],\n",
       "       [-0.42697475, -0.53669021,  1.6289552 , ...,  0.45048209,\n",
       "        -0.49615364,  1.18913227]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca = pca.transform(X_scaled)[:, :n_components]\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need 7 PC to have a variance of 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
