{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1\n",
    "\n",
    "Boosting is an ensemble technique that combines multiple weak learners to create a strong learner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2\n",
    "\n",
    "Advantages: Boosting improves model accuracy and is robust. Limitations: It can be sensitive to noisy data and may lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3\n",
    "\n",
    "Boosting combines weak models by giving more weight to misclassified examples in successive iterations, creating a strong model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4\n",
    "\n",
    "Common boosting algorithms include AdaBoost, Gradient Boosting, and XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5\n",
    "\n",
    "Common parameters include learning rate, number of estimators (iterations), and base learner type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6\n",
    "\n",
    "Boosting combines weak learners by giving more importance to samples that were misclassified in previous iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7\n",
    "\n",
    "AdaBoost combines weak learners and assigns weights to data points, emphasizing misclassified samples in each iteration, creating a strong learner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8\n",
    "\n",
    "AdaBoost primarily uses the exponential loss function (also known as the AdaBoost loss function) to adjust the weights of misclassified samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9\n",
    "\n",
    "In AdaBoost, misclassified sample weights are increased after each iteration, making them more important in the next round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10\n",
    "\n",
    "Increasing the number of estimators in AdaBoost can improve the model's performance but may increase the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
